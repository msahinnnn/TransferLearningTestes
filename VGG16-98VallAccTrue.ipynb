{
  "cells": [
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "id": "pHB7Qf16LBNJ",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "0431fd63-2054-44f8-b051-1a68e295538b"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Mounted at /content/gdrive\n"
          ]
        }
      ],
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/gdrive')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {
        "id": "pb5GxaT5LFPg",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "83ce12c7-00c8-41f8-9db2-5e17de43e50f"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "/content/gdrive/My Drive/Colab Notebooks/DerinOgrenme\n",
            "deneme.jpg      MobileNet61.h5  \u001b[0m\u001b[01;34mtest\u001b[0m/       VGG19_2.h5  VGG19_5.h5\n",
            "kekik.jpg       MobileNet65.h5  VGG16_1.h5  VGG19_3.h5  VGG19_6.h5\n",
            "MobileNet38.h5  MobileNet73.h5  VGG19_1.h5  VGG19_4.h5  VGG19_98.h5\n"
          ]
        }
      ],
      "source": [
        "%cd gdrive/My Drive/Colab Notebooks/DerinOgrenme/\n",
        "%ls"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "metadata": {
        "id": "_BpY_Xx3LK6z"
      },
      "outputs": [],
      "source": [
        "from tensorflow.keras.applications.vgg16  import VGG16\n",
        "from tensorflow.keras.layers import Input\n",
        "from tensorflow.keras.models import Model\n",
        "from keras.preprocessing.image import ImageDataGenerator\n",
        "from keras.models import Sequential, Model\n",
        "from keras.layers import Conv2D, MaxPooling2D\n",
        "from keras.layers import Activation, Dropout, Flatten, Dense, BatchNormalization\n",
        "from keras import backend as K\n",
        "from PIL import Image\n",
        "\n",
        "\n",
        "img_width, img_height = 224, 224\n",
        "\n",
        "imageChannels = 3\n",
        "batchSize = 100\n",
        "epoch = 20\n",
        "classMode = 'categorical'\n",
        "fcDense = 3\n",
        "fcActivation = 'softmax' #son katman\n",
        "optimizer = 'adam'\n",
        "loss = 'binary_crossentropy'\n",
        "metrics = 'accuracy'\n",
        "train_ornek_sayisi = 3000\n",
        "validation_ornek_sayisi = 900 \n",
        "\n",
        "\n",
        "train_data_yolu = 'test/train'\n",
        "validation_data_yolu = 'test/validation'\n",
        "\n",
        "\n",
        "if K.image_data_format() == 'channels_first':\n",
        "    input_shape = (3, img_width, img_height)\n",
        "else:\n",
        "    input_shape = (img_width, img_height, 3)\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 4,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Vf25ZHVNLLMP",
        "outputId": "f11dd58a-1c9c-4c68-ceb5-607a39c66d18"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Downloading data from https://storage.googleapis.com/tensorflow/keras-applications/vgg16/vgg16_weights_tf_dim_ordering_tf_kernels_notop.h5\n",
            "58892288/58889256 [==============================] - 0s 0us/step\n",
            "58900480/58889256 [==============================] - 0s 0us/step\n",
            "Model: \"model\"\n",
            "_________________________________________________________________\n",
            " Layer (type)                Output Shape              Param #   \n",
            "=================================================================\n",
            " input_1 (InputLayer)        [(None, 224, 224, 3)]     0         \n",
            "                                                                 \n",
            " block1_conv1 (Conv2D)       (None, 224, 224, 64)      1792      \n",
            "                                                                 \n",
            " block1_conv2 (Conv2D)       (None, 224, 224, 64)      36928     \n",
            "                                                                 \n",
            " block1_pool (MaxPooling2D)  (None, 112, 112, 64)      0         \n",
            "                                                                 \n",
            " block2_conv1 (Conv2D)       (None, 112, 112, 128)     73856     \n",
            "                                                                 \n",
            " block2_conv2 (Conv2D)       (None, 112, 112, 128)     147584    \n",
            "                                                                 \n",
            " block2_pool (MaxPooling2D)  (None, 56, 56, 128)       0         \n",
            "                                                                 \n",
            " block3_conv1 (Conv2D)       (None, 56, 56, 256)       295168    \n",
            "                                                                 \n",
            " block3_conv2 (Conv2D)       (None, 56, 56, 256)       590080    \n",
            "                                                                 \n",
            " block3_conv3 (Conv2D)       (None, 56, 56, 256)       590080    \n",
            "                                                                 \n",
            " block3_pool (MaxPooling2D)  (None, 28, 28, 256)       0         \n",
            "                                                                 \n",
            " block4_conv1 (Conv2D)       (None, 28, 28, 512)       1180160   \n",
            "                                                                 \n",
            " block4_conv2 (Conv2D)       (None, 28, 28, 512)       2359808   \n",
            "                                                                 \n",
            " block4_conv3 (Conv2D)       (None, 28, 28, 512)       2359808   \n",
            "                                                                 \n",
            " block4_pool (MaxPooling2D)  (None, 14, 14, 512)       0         \n",
            "                                                                 \n",
            " block5_conv1 (Conv2D)       (None, 14, 14, 512)       2359808   \n",
            "                                                                 \n",
            " block5_conv2 (Conv2D)       (None, 14, 14, 512)       2359808   \n",
            "                                                                 \n",
            " block5_conv3 (Conv2D)       (None, 14, 14, 512)       2359808   \n",
            "                                                                 \n",
            " block5_pool (MaxPooling2D)  (None, 7, 7, 512)         0         \n",
            "                                                                 \n",
            " flatten (Flatten)           (None, 25088)             0         \n",
            "                                                                 \n",
            " fc1 (Dense)                 (None, 128)               3211392   \n",
            "                                                                 \n",
            " fc2 (Dense)                 (None, 128)               16512     \n",
            "                                                                 \n",
            " fc3 (Dense)                 (None, 128)               16512     \n",
            "                                                                 \n",
            " fc4 (Dense)                 (None, 256)               33024     \n",
            "                                                                 \n",
            " fc5 (Dense)                 (None, 256)               65792     \n",
            "                                                                 \n",
            " fc6 (Dense)                 (None, 256)               65792     \n",
            "                                                                 \n",
            " fc7 (Dense)                 (None, 256)               65792     \n",
            "                                                                 \n",
            " fc8 (Dense)                 (None, 512)               131584    \n",
            "                                                                 \n",
            " fc9 (Dense)                 (None, 512)               262656    \n",
            "                                                                 \n",
            " fc10 (Dense)                (None, 512)               262656    \n",
            "                                                                 \n",
            " fc11 (Dense)                (None, 512)               262656    \n",
            "                                                                 \n",
            " fc12 (Dense)                (None, 512)               262656    \n",
            "                                                                 \n",
            " fc13 (Dense)                (None, 512)               262656    \n",
            "                                                                 \n",
            " predictions (Dense)         (None, 3)                 1539      \n",
            "                                                                 \n",
            "=================================================================\n",
            "Total params: 19,635,907\n",
            "Trainable params: 19,635,907\n",
            "Non-trainable params: 0\n",
            "_________________________________________________________________\n"
          ]
        }
      ],
      "source": [
        "input = Input(input_shape)\n",
        "\n",
        "model = VGG16(\n",
        "    include_top = False,\n",
        "    weights = 'imagenet',\n",
        "    input_tensor = input,\n",
        "    classes = 3\n",
        ")\n",
        "\n",
        "flat1 = Flatten()(model.layers[-1].output)\n",
        "\n",
        "class1 = Dense(128, activation='relu', name='fc1')(flat1)\n",
        "class2 = Dense(128, activation='relu', name='fc2')(class1)\n",
        "class3 = Dense(128, activation='relu', name='fc3')(class2)\n",
        "\n",
        "class4 = Dense(256, activation='relu', name='fc4')(class3)\n",
        "class5= Dense(256, activation='relu', name='fc5')(class4)\n",
        "class6 = Dense(256, activation='relu', name='fc6')(class5)\n",
        "class7= Dense(256, activation='relu', name='fc7')(class6)\n",
        "\n",
        "class8 = Dense(512, activation='relu', name='fc8')(class7)\n",
        "class9 = Dense(512, activation='relu', name='fc9')(class8)\n",
        "class10 = Dense(512, activation='relu', name='fc10')(class9)\n",
        "class11= Dense(512, activation='relu', name='fc11')(class10)\n",
        "class12 = Dense(512, activation='relu', name='fc12')(class11)\n",
        "class13= Dense(512, activation='relu', name='fc13')(class12)\n",
        "\n",
        "output = Dense(fcDense, activation='softmax', name='predictions')(class13)\n",
        "\n",
        "model = Model(inputs=model.inputs, outputs=output)\n",
        "\n",
        "model.summary()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 5,
      "metadata": {
        "id": "zjMcGsrGPAmY"
      },
      "outputs": [],
      "source": [
        "from tensorflow.keras.callbacks import EarlyStopping\n",
        "\n",
        "model.compile(\n",
        "    optimizer='adam',\n",
        "    loss='categorical_crossentropy',\n",
        "    metrics=['accuracy'],\n",
        ")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 6,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "4-qvzu05QJdc",
        "outputId": "dadc089c-5def-4171-9cbd-5e8fce13a66c"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Found 2400 images belonging to 3 classes.\n",
            "Found 600 images belonging to 3 classes.\n",
            "Found 900 images belonging to 3 classes.\n"
          ]
        }
      ],
      "source": [
        "from tensorflow.keras.applications.vgg16 import preprocess_input\n",
        "\n",
        "\n",
        "train_datagen=ImageDataGenerator(preprocessing_function=preprocess_input, validation_split=0.2, horizontal_flip=True, zoom_range=0.2, rescale=1./255, rotation_range=45, width_shift_range=0.2,\n",
        "                                 height_shift_range=0.2, shear_range=0.2, fill_mode='nearest')\n",
        "test_datagen=ImageDataGenerator(preprocessing_function=preprocess_input)\n",
        "\n",
        "train_generator = train_datagen.flow_from_directory(\n",
        "    train_data_yolu,\n",
        "    target_size=(img_width, img_height),\n",
        "    batch_size=batchSize,\n",
        "    subset=\"training\",\n",
        "    class_mode=classMode\n",
        ")\n",
        "validation_generator = train_datagen.flow_from_directory(\n",
        "    train_data_yolu,\n",
        "    target_size=(img_width, img_height),\n",
        "    batch_size=batchSize,\n",
        "    subset=\"validation\",\n",
        "    class_mode=classMode\n",
        ")\n",
        "test_generator = test_datagen.flow_from_directory(\n",
        "    validation_data_yolu,\n",
        "    target_size=(img_width, img_height),\n",
        "    batch_size=batchSize,\n",
        "    class_mode=classMode\n",
        ")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 7,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "DOWwER8BUN9L",
        "outputId": "c934ef4f-b588-4aac-96eb-7d9ef96f44bd"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/20\n",
            "24/24 [==============================] - 1695s 70s/step - loss: 1.3086 - accuracy: 0.3208 - val_loss: 1.0971 - val_accuracy: 0.3333\n",
            "Epoch 2/20\n",
            "24/24 [==============================] - 57s 2s/step - loss: 1.0957 - accuracy: 0.3383 - val_loss: 1.0733 - val_accuracy: 0.3333\n",
            "Epoch 3/20\n",
            "24/24 [==============================] - 57s 2s/step - loss: 1.0962 - accuracy: 0.3267 - val_loss: 1.1015 - val_accuracy: 0.3333\n",
            "Epoch 4/20\n",
            "24/24 [==============================] - 57s 2s/step - loss: 1.1204 - accuracy: 0.4108 - val_loss: 1.0202 - val_accuracy: 0.7217\n",
            "Epoch 5/20\n",
            "24/24 [==============================] - 57s 2s/step - loss: 1.2212 - accuracy: 0.4137 - val_loss: 1.0472 - val_accuracy: 0.3333\n",
            "Epoch 6/20\n",
            "24/24 [==============================] - 57s 2s/step - loss: 0.9122 - accuracy: 0.5021 - val_loss: 0.6990 - val_accuracy: 0.6650\n",
            "Epoch 7/20\n",
            "24/24 [==============================] - 57s 2s/step - loss: 0.6666 - accuracy: 0.6604 - val_loss: 0.5512 - val_accuracy: 0.6950\n",
            "Epoch 8/20\n",
            "24/24 [==============================] - 57s 2s/step - loss: 0.6369 - accuracy: 0.6700 - val_loss: 0.5595 - val_accuracy: 0.6900\n",
            "Epoch 9/20\n",
            "24/24 [==============================] - 57s 2s/step - loss: 0.7411 - accuracy: 0.6196 - val_loss: 0.5523 - val_accuracy: 0.7100\n",
            "Epoch 10/20\n",
            "24/24 [==============================] - 57s 2s/step - loss: 0.6111 - accuracy: 0.7046 - val_loss: 0.5005 - val_accuracy: 0.7700\n",
            "Epoch 11/20\n",
            "24/24 [==============================] - 57s 2s/step - loss: 0.5216 - accuracy: 0.7817 - val_loss: 0.3431 - val_accuracy: 0.8900\n",
            "Epoch 12/20\n",
            "24/24 [==============================] - 57s 2s/step - loss: 0.3697 - accuracy: 0.8675 - val_loss: 0.1791 - val_accuracy: 0.9533\n",
            "Epoch 13/20\n",
            "24/24 [==============================] - 57s 2s/step - loss: 0.2947 - accuracy: 0.9050 - val_loss: 0.1990 - val_accuracy: 0.9350\n",
            "Epoch 14/20\n",
            "24/24 [==============================] - 57s 2s/step - loss: 0.3093 - accuracy: 0.9100 - val_loss: 0.2338 - val_accuracy: 0.9600\n",
            "Epoch 15/20\n",
            "24/24 [==============================] - 58s 2s/step - loss: 0.4106 - accuracy: 0.8371 - val_loss: 0.2742 - val_accuracy: 0.9050\n",
            "Epoch 16/20\n",
            "24/24 [==============================] - 57s 2s/step - loss: 0.2367 - accuracy: 0.9129 - val_loss: 0.0915 - val_accuracy: 0.9750\n",
            "Epoch 17/20\n",
            "24/24 [==============================] - 58s 2s/step - loss: 0.1833 - accuracy: 0.9392 - val_loss: 0.1839 - val_accuracy: 0.9817\n",
            "Epoch 18/20\n",
            "24/24 [==============================] - 58s 2s/step - loss: 0.2208 - accuracy: 0.9275 - val_loss: 0.2176 - val_accuracy: 0.9533\n",
            "Epoch 19/20\n",
            "24/24 [==============================] - 57s 2s/step - loss: 0.2018 - accuracy: 0.9337 - val_loss: 0.1049 - val_accuracy: 0.9783\n",
            "Epoch 20/20\n",
            "24/24 [==============================] - 57s 2s/step - loss: 0.1682 - accuracy: 0.9463 - val_loss: 0.0721 - val_accuracy: 0.9800\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<keras.callbacks.History at 0x7f63a8576d90>"
            ]
          },
          "metadata": {},
          "execution_count": 7
        }
      ],
      "source": [
        "model.fit(\n",
        "    train_generator,\n",
        "    validation_data=validation_generator,\n",
        "    validation_steps=600//batchSize,\n",
        "    steps_per_epoch=2400//batchSize,\n",
        "    batch_size=480,\n",
        "    epochs=epoch,\n",
        "    verbose=1\n",
        ")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 8,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "MtcF8lpgj-h7",
        "outputId": "ea85f9b8-579f-4e32-e10b-4e80dff87231"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[[2.5037427e-05 4.2850923e-05 9.9993205e-01]]\n"
          ]
        }
      ],
      "source": [
        "from keras.preprocessing.image import load_img\n",
        "from keras.preprocessing.image import img_to_array\n",
        "\n",
        "img = load_img('kekik.jpg', grayscale=False, color_mode='rgb', target_size=(img_width, img_height))\n",
        "image = img_to_array(img)\n",
        "image = image.reshape((1, image.shape[0], image.shape[1], image.shape[2]))\n",
        "image = preprocess_input(image)\n",
        "\n",
        "yhat = model.predict(image)\n",
        "print(yhat)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 9,
      "metadata": {
        "id": "oeojYyKgY57Y"
      },
      "outputs": [],
      "source": [
        "model.save(\"VGG16-95.h5\")\n"
      ]
    }
  ],
  "metadata": {
    "colab": {
      "collapsed_sections": [],
      "name": "OnIslemeliModel.ipynb",
      "provenance": [],
      "toc_visible": true
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "nbformat": 4,
  "nbformat_minor": 0
}